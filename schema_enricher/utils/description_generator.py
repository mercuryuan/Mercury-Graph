import json
import os
import time

import config
from graph_construction.graph_to_mschema import get_table_schema
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from tqdm import tqdm


class TableSchemaDescriber:
    def __init__(self, db_path: str, model_name: str = "gpt-3.5-turbo"):
        """
        åˆå§‹åŒ–è¡¨ç»“æ„æè¿°ç”Ÿæˆå·¥å…·ã€‚
        :param db_path: æ•°æ®åº“è·¯å¾„ã€‚
        :param model_name: ä½¿ç”¨çš„ LLM æ¨¡å‹åç§°ã€‚
        """
        self.db_path = db_path
        self.llm = ChatOpenAI(model=model_name)
        self.output_dir = config.GENERATED_DESCRIPTIONS
        os.makedirs(self.output_dir, exist_ok=True)
        self.log_file = os.path.join(config.SCHEMA_ENRICHER, "Database_Description_Process.log")
        self.conversation_history = []  # å­˜å‚¨å…¨å±€å¯¹è¯å†å²
        self._is_system_added = False  # æ ‡è®°æ˜¯å¦å·²æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯

    def get_schema(self, table_name: str = None):
        """
        è·å–æ•°æ®åº“çš„è¡¨ç»“æ„ä¿¡æ¯ã€‚
        :param table_name: éœ€è¦æè¿°çš„è¡¨åï¼ˆå¯é€‰ï¼‰ã€‚
        :return: (db_name, table_list, table_name, table_schema)
        """
        return get_table_schema(self.db_path, table_name, show_tables=False)

    def generate_prompt(self, table_name: str, table_schema: str) -> list:
        """
        ç”Ÿæˆæè¿°è¡¨ç»“æ„çš„å¤šè½®å¯¹è¯æç¤ºè¯ã€‚
        :param table_name: éœ€è¦æè¿°çš„è¡¨åã€‚
        :param table_schema: è¯¥è¡¨çš„è¡¨ç»“æ„ä¿¡æ¯ã€‚
        :return: ç”Ÿæˆçš„å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ã€‚
        """
        user_message = f"""Table Name: {table_name}
        Table Schema:  
        {table_schema}

        Please output the result in the following JSON format:  

        ```json
        {{
            "{table_name}": [
                {{
                    "columns": {{
                        "column_name1": "description of column1",
                        "column_name2": "description of column2"
                    }},
                    "table_description": "The overall description of the table is to be generated"
                }}
            ]
        }}
        ```"""
        return [{"role": "user", "content": user_message}]

    def call_llm(self, messages: list) -> str:
        """
        è°ƒç”¨ LLM è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œå¹¶ç»´æŠ¤ä¸Šä¸‹æ–‡å†å²ã€‚
        è°ƒç”¨LLMï¼ˆæ··åˆæ¨¡å¼ï¼šsystem + æ‰€æœ‰assistantå›å¤ + æœ€æ–°useræ¶ˆæ¯ï¼‰
        :param messages: æœ¬æ¬¡å¯¹è¯çš„æ–°æ¶ˆæ¯åˆ—è¡¨ã€‚
        :return: LLM ç”Ÿæˆçš„ JSON æ ¼å¼æè¿°ã€‚
        """
        # é¦–æ¬¡è°ƒç”¨æ—¶æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        if not self._is_system_added:
            system_msg = {
                "role": "system",
                "content": """
### You are a professional database modeling expert. Based on the following table schema, generate detailed descriptions for each column.

1. **Exact Name Matching**
   - Use column/table names exactly as shown in schema (case-sensitive)
   - Never modify or translate names

2. **Strict JSON Format**
   - Output must precisely match specified JSON structure
   - No syntax deviations (commas, brackets, quotes)

3. **Pure Semantic Descriptions**
   - Describe ONLY the business meaning of column names
   - If there was a description, do not omit the original meaning, but maintain the style.
   - contain necessary detailsï¼š
   * "Sex": "The gender of the student, represented by a single character."

4. **Table Description Synthesis**
   - State core business purpose
   - Derive from column descriptions

5. **Concise Professional Style**
   - â‰¤15 words per description
   - Active voice
   - Easily understandable by non-technical users

6. **Canonical Definition Format**
   - Start every description with "The"
   - Example: "The gender of the student..."
   - FORBIDDEN PHRASES:
     * "This column represents..."
     * "The table contains..."

7. **Style Unification**
   - Maintain consistent:
     * Sentence structures
     * Terminology
     * Phrasing patterns
   - Critical for semantic similarity matching

8. **Historical Consistency**
   - When available:
     * Reuse terminology from past descriptions
     * Match existing patterns
     * Maintain conceptual alignment
   - Example: If "ID" was "The unique identifier...", keep this format

### Validation Checklist:
âœ“ Name casing âœ“ JSON structure âœ“ No tech details
âœ“ "The"-style âœ“ Length limits âœ“ Historical alignment
    """
            }
            self.conversation_history.insert(0, system_msg)
            self._is_system_added = True

        # === æ ¸å¿ƒä¿®æ”¹ç‚¹ ===
        # æ„é€ æœ‰æ•ˆå†å²ï¼šsystem + æ‰€æœ‰assistantæ¶ˆæ¯ + æœ€æ–°useræ¶ˆæ¯
        effective_history = [
                                msg for msg in self.conversation_history
                                if msg["role"] in ["system", "assistant"]
                            ] + messages[-1:]  # åªå–messagesçš„æœ€åä¸€æ¡ï¼ˆæœ€æ–°useræ¶ˆæ¯ï¼‰

        # åŸå§‹å†å²ä»ç„¶å®Œæ•´è®°å½•ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        self.conversation_history.extend(messages)

        # # è°ƒè¯•ä¿¡æ¯ï¼ˆæ˜¾ç¤ºå®é™…ä½¿ç”¨çš„å†å²ï¼‰
        # self.log(f"\n[DEBUG] æœ‰æ•ˆå¯¹è¯å†å² (å…± {len(effective_history)} æ¡):")
        # for i, msg in enumerate(effective_history, 1):
        #     role = msg["role"]
        #     content_preview = msg["content"][:80].replace("\n", " ")
        #     self.log(f"  {i}. {role}: {content_preview}...")

        # è°ƒç”¨LLMï¼ˆä¼ å…¥ç²¾ç®€åçš„å†å²ï¼‰
        response = self.llm.invoke(effective_history).content.strip()

        # è®°å½•å®Œæ•´å†å²ï¼ˆåŒ…å«æœ¬æ¬¡äº¤äº’ï¼‰
        self.conversation_history.append({"role": "assistant", "content": response})
        return self.clean_response(response)

    @staticmethod
    def clean_response(response: str) -> str:
        """
        æ¸…ç† LLM çš„è¾“å‡ºï¼Œç¡®ä¿ JSON æ ¼å¼æ­£ç¡®ã€‚
        :param response: LLM åŸå§‹è¾“å‡ºã€‚
        :return: æ¸…ç†åçš„ JSON å­—ç¬¦ä¸²ã€‚
        """
        response = response.strip()
        if response.startswith("```json"):
            response = response.replace("```json", "", 1).strip()
        if response.endswith("```"):
            response = response[:-3].strip()
        response = response.replace("\t", "").replace("\r", "")
        return response

    def save_description(self, db_name: str, table_name: str, description: str):
        """
        ä¿å­˜è¡¨æè¿°åˆ° JSON æ–‡ä»¶ã€‚
        :param db_name: æ•°æ®åº“åç§°ã€‚
        :param table_name: è¡¨åã€‚
        :param description: ç”Ÿæˆçš„è¡¨æè¿°ã€‚
        """
        file_path = os.path.join(self.output_dir, f"{db_name}.json")
        new_data = json.loads(description)

        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
            existing_data.update(new_data)
        else:
            existing_data = new_data

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=4)

    def describe_table(self, table_name: str):
        """ç”Ÿæˆè¡¨çš„åˆ—æè¿°å¹¶ä¿å­˜ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰"""
        try:
            db_name, _, _, table_schema = self.get_schema(table_name)
            messages = self.generate_prompt(table_name, table_schema)
            description = self.call_llm(messages)  # è°ƒç”¨æ—¶ä¼šè‡ªåŠ¨ç»´æŠ¤å†å²
            self.save_description(db_name, table_name, description)
        except Exception as e:
            self.log(f"âŒ å¤„ç†è¡¨ {table_name} å¤±è´¥: {e}")
            self.conversation_history = []  # å‡ºé”™æ—¶æ¸…ç©ºå†å²ï¼ˆå¯é€‰ï¼‰

    def describe_database(self):
        """
        éå†æ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨ï¼Œå¹¶ä¸ºæ¯ä¸ªè¡¨ç”Ÿæˆæè¿°ã€‚
        ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå¤„ç†è¿›åº¦ï¼Œå¹¶å¯¹å¤±è´¥çš„è¡¨è¿›è¡Œæœ€å¤š 3 æ¬¡é‡è¯•ã€‚
        """

        db_name, table_list, _, _ = self.get_schema()
        start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
        start_timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(start_time))

        self.log(f"[{start_timestamp}] ğŸš€ å¼€å§‹å¤„ç†æ•°æ®åº“: {db_name}, åŒ…å« {len(table_list)} å¼ è¡¨")

        for table_name in tqdm(table_list, desc=f"Processing {db_name} Tables"):
            attempt = 0
            success = False

            while attempt < 3 and not success:
                try:
                    _, _, table_name, table_schema = self.get_schema(table_name)
                    messages = self.generate_prompt(table_name, table_schema)
                    description = self.call_llm(messages)
                    self.save_description(db_name, table_name, description)
                    self.log(f"âœ… æˆåŠŸå¤„ç†è¡¨: {table_name}")
                    success = True
                except json.JSONDecodeError as e:
                    self.log(f"âŒ è§£æ JSON å¤±è´¥: {table_name}, å°è¯• {attempt + 1}/3, é”™è¯¯: {e}")
                except Exception as e:
                    self.log(f"âŒ å¤„ç†è¡¨å¤±è´¥: {table_name}, å°è¯• {attempt + 1}/3, é”™è¯¯: {e}")
                finally:
                    attempt += 1
                    time.sleep(1)  # é¿å…çŸ­æ—¶é—´å†…é¢‘ç¹è°ƒç”¨

        end_time = time.time()  # è®°å½•ç»“æŸæ—¶é—´
        end_timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(end_time))
        elapsed_time = end_time - start_time

        self.log(f"[{end_timestamp}] ğŸ‰ æ•°æ®åº“ {db_name} å¤„ç†å®Œæˆï¼è€—æ—¶: {elapsed_time:.2f} ç§’")

    def log(self, message: str):
        """
        è®°å½•æ—¥å¿—åˆ°æ–‡ä»¶ï¼Œå¹¶æ‰“å°ã€‚
        :param message: éœ€è¦è®°å½•çš„æ—¥å¿—å†…å®¹ã€‚
        """
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(message + "\n")
        print(message)

    import time
    from tqdm import tqdm
    import json


# ç¤ºä¾‹è°ƒç”¨
if __name__ == "__main__":
    # db_path = "../../graphs_repo/spider/bike_1"
    # db_path = os.path.join(config.GRAPHS_REPO, "bird", "shakespeare")
    db_path = os.path.join(config.GRAPHS_REPO, "bird", "books")
    describer = TableSchemaDescriber(db_path)
    # å¤„ç†å•è¡¨
    # describer.describe_table("Student")
    # å¤„ç†å½“å‰TableSchemaDescriberæ‰€åœ¨çš„æ•°æ®åº“
    describer.describe_database()
