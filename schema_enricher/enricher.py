import os
import time

from tqdm import tqdm

from graph_construction.neo4j_data_migration import load_graph_to_neo4j
from schema_enricher.utils.description_generator import TableSchemaDescriber
from schema_enricher.utils.description_injector import inject_descriptions


class Enricher:
    """
    Enricher ç±»ç”¨äºå¢å¼ºæ•°æ®åº“çš„å…ƒä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    1. ä¸ºè¡¨å’Œåˆ—ç”Ÿæˆæè¿°ä¿¡æ¯ã€‚
    2. åœ¨å¤–é”®è¿æ¥ä¸å…¨çš„æƒ…å†µä¸‹ï¼ŒåŸºäºä¸šåŠ¡é€»è¾‘æ¨æ–­å¯èƒ½çš„å¤–é”®å…³ç³»ã€‚
    """

    def __init__(self, ds_root: str = "../graphs_repo/", log_file: str = "./Enrich_Process.log"):
        """
        åˆå§‹åŒ– Enricherã€‚

        :param ds_root: æ•°æ®é›†æ ¹ç›®å½•
        :param log_file: å¤„ç†æ—¥å¿—å­˜å‚¨è·¯å¾„ã€‚
        """
        self.ds_root = ds_root
        self.log_file = log_file
        os.makedirs(os.path.dirname(log_file), exist_ok=True)  # ç¡®ä¿æ—¥å¿—æ–‡ä»¶å¤¹å­˜åœ¨

    def log(self, message: str):
        """ è®°å½•æ—¥å¿—ä¿¡æ¯åˆ°æ–‡ä»¶å¹¶æ‰“å°åˆ°æ§åˆ¶å° """
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        log_msg = f"[{timestamp}] {message}"
        with open(self.log_file, "a", encoding="utf-8") as log:
            log.write(log_msg + "\n")
        print(log_msg)

    def enrich_description(self, db_path: str):
        """
        ç”ŸæˆæŒ‡å®šæ•°æ®åº“çš„è¡¨æè¿°ï¼Œå¹¶è®°å½•æ—¥å¿—ã€‚

        :param db_path: æ•°æ®åº“æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        """
        db_name = os.path.basename(db_path)  # æ•°æ®åº“åç§°
        description_file = f"./generated_descriptions/{db_name}.json"

        # 1. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨æè¿°æ–‡ä»¶
        if os.path.exists(description_file):
            self.log(f"â© è·³è¿‡ {db_name}ï¼Œæè¿°æ–‡ä»¶å·²å­˜åœ¨ã€‚")
            return

        self.log(f"ğŸš€ å¼€å§‹å¤„ç†æ•°æ®åº“: {db_name}")

        describer = TableSchemaDescriber(db_path)

        try:
            describer.describe_database()
            self.log(f"âœ… {db_name} å¤„ç†å®Œæˆï¼")
        except Exception as e:
            self.log(f"âŒ å¤„ç† {db_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    def infer_foreign_keys(self):
        """
        ï¼ˆå ä½å‡½æ•°ï¼‰ç”¨äºæ¨æ–­æ•°æ®åº“çš„å¤–é”®å…³ç³»ï¼Œå¹¶è¡¥å……åˆ°æ•°æ®åº“æ¨¡å¼ä¸­ã€‚
        """
        print("ğŸ” å¤–é”®æ¨æ–­åŠŸèƒ½å¾…å®ç°...")

    def enrich_schema(self, dataset_name: str):
        """
        éå†æ•°æ®é›†ç›®å½•ï¼Œå¯¹æ‰€æœ‰æ•°æ®åº“æ‰§è¡Œ enrich_descriptionã€‚

        :param dataset_name: æ•°æ®é›†åç§°ï¼Œå¿…é¡»æ˜¯ 'spider' æˆ– 'bird'ã€‚
        """
        if dataset_name not in {"spider", "bird"}:
            raise ValueError("dataset_name å¿…é¡»æ˜¯ 'spider' æˆ– 'bird'")

        ds_path = os.path.join(self.ds_root, dataset_name)

        if not os.path.exists(ds_path):
            raise FileNotFoundError(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {ds_path}")

        self.log(f"ğŸ“‚ å¼€å§‹å¤„ç†æ•°æ®é›†: {dataset_name}ï¼Œè·¯å¾„: {ds_path}")

        db_folders = [os.path.join(ds_path, db) for db in os.listdir(ds_path) if
                      os.path.isdir(os.path.join(ds_path, db))]

        for db_path in tqdm(db_folders, desc=f"Processing {dataset_name} databases"):
            # # 1. å¯¹æ¯ä¸ªæ•°æ®åº“æ‰§è¡Œ descriptionç”Ÿæˆï¼Œå·²å®Œæˆå¯æ³¨é‡Š
            # self.enrich_description(db_path)
            # # 2. å¯¹æ¯ä¸ªæ•°æ®åº“æ‰§è¡Œ descriptionæ³¨å…¥
            db_name = os.path.basename(db_path)
            inject_descriptions(dataset_name,db_name)
            pass

        self.log(f"ğŸ‰ æ•°æ®é›† {dataset_name} å¤„ç†å®Œæˆï¼")


if __name__ == "__main__":
    enricher = Enricher(ds_root="../graphs_repo/")
    """
    æ‰€æœ‰æ­¥éª¤å†™åœ¨enrich_schemaå‡½æ•°ä¸­ï¼Œè°ƒç”¨ä¸€æ¬¡å°±è‡ªåŠ¨å®Œæˆenrichçš„æ‰€æœ‰æ­¥éª¤,åªéœ€ä¼ å…¥æ•°æ®é›†åç§°å³å¯ã€‚
    """
    # enricher.enrich_schema("spider")  # å¤„ç† spider æ•°æ®é›†
    # enricher.enrich_schema("bird")    # å¤„ç† bird æ•°æ®é›†

    #æŸ¥çœ‹neo4jã€‚åŠ¨æ€æµ‹è¯•æ•ˆæœ
    load_graph_to_neo4j("spider", "academic")
